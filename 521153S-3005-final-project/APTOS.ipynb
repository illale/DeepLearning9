{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b2f1274-9c89-4e50-a03a-7a14b9e7fa32",
   "metadata": {
    "id": "9b2f1274-9c89-4e50-a03a-7a14b9e7fa32"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import kagglehub\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from sklearn.metrics import cohen_kappa_score, precision_score, recall_score, accuracy_score\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd28dd97-f6ba-49f7-a8c4-f8199b55c82f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dd28dd97-f6ba-49f7-a8c4-f8199b55c82f",
    "outputId": "6382e7da-4231-47ce-822b-121de03658b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fb435e6-39c9-4ddd-b9ee-80b792cb9e46",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1fb435e6-39c9-4ddd-b9ee-80b792cb9e46",
    "outputId": "e6c7458d-42f8-4ad1-c10f-c40d2a8f3374"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.5)\n",
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/mariaherrerot/aptos2019?dataset_version_number=3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8.01G/8.01G [00:40<00:00, 213MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /root/.cache/kagglehub/datasets/mariaherrerot/aptos2019/versions/3\n"
     ]
    }
   ],
   "source": [
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"mariaherrerot/aptos2019\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7c38669-6d83-430c-b6bd-7332e813235f",
   "metadata": {
    "id": "e7c38669-6d83-430c-b6bd-7332e813235f"
   },
   "outputs": [],
   "source": [
    "batch_size = 24\n",
    "num_classes = 5  # 5 DR levels\n",
    "learning_rate = 0.0001\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acc8788e-4e29-46ab-b114-1ee851f44136",
   "metadata": {
    "id": "acc8788e-4e29-46ab-b114-1ee851f44136"
   },
   "outputs": [],
   "source": [
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea91fdc7-8822-44fe-a4fa-4a26943e38ae",
   "metadata": {
    "id": "ea91fdc7-8822-44fe-a4fa-4a26943e38ae"
   },
   "outputs": [],
   "source": [
    "class APTOSDataset(Dataset):\n",
    "    def __init__(self, ann_file, image_dir, transform=None, test=False):\n",
    "        self.ann_file = ann_file\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        self.test = test\n",
    "\n",
    "        self.data = self.load_data()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.get_item(index)\n",
    "\n",
    "    # 1. single image\n",
    "    def load_data(self):\n",
    "        df = pd.read_csv(self.ann_file)\n",
    "\n",
    "        data = []\n",
    "        for _, row in df.iterrows():\n",
    "            file_info = dict()\n",
    "            file_info['img_path'] = os.path.join(self.image_dir, row['id_code'] + \".png\")\n",
    "            file_info['diagnosis'] = row['diagnosis']\n",
    "            data.append(file_info)\n",
    "        return data\n",
    "\n",
    "    def get_item(self, index):\n",
    "        data = self.data[index]\n",
    "        img = Image.open(data['img_path']).convert('RGB')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if not self.test:\n",
    "            label = torch.tensor(data['diagnosis'], dtype=torch.int64)\n",
    "            return img, label\n",
    "        else:\n",
    "            return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "KSBeD8APzTVw",
   "metadata": {
    "id": "KSBeD8APzTVw"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(preds, labels, per_class=False):\n",
    "    kappa = cohen_kappa_score(labels, preds, weights='quadratic')\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    precision = precision_score(labels, preds, average='weighted', zero_division=0)\n",
    "    recall = recall_score(labels, preds, average='weighted', zero_division=0)\n",
    "\n",
    "    # Calculate and print precision and recall for each class\n",
    "    if per_class:\n",
    "        precision_per_class = precision_score(labels, preds, average=None, zero_division=0)\n",
    "        recall_per_class = recall_score(labels, preds, average=None, zero_division=0)\n",
    "        return kappa, accuracy, precision, recall, precision_per_class, recall_per_class\n",
    "\n",
    "    return kappa, accuracy, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fYYpnJXZzQ79",
   "metadata": {
    "id": "fYYpnJXZzQ79"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, device, test_only=False, prediction_path='./test_predictions.csv'):\n",
    "    model.eval()\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_image_ids = []\n",
    "\n",
    "    with tqdm(total=len(test_loader), desc=f'Evaluating', unit=' batch', file=sys.stdout) as pbar:\n",
    "        for i, data in enumerate(test_loader):\n",
    "\n",
    "            if test_only:\n",
    "                images = data\n",
    "            else:\n",
    "                images, labels = data\n",
    "\n",
    "            if not isinstance(images, list):\n",
    "                images = images.to(device)  # single image case\n",
    "            else:\n",
    "                images = [x.to(device) for x in images]  # dual images case\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = model(images)\n",
    "                preds = torch.argmax(outputs, 1)\n",
    "\n",
    "            if not isinstance(images, list):\n",
    "                # single image case\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                image_ids = [\n",
    "                    os.path.basename(test_loader.dataset.data[idx]['img_path']) for idx in\n",
    "                    range(i * test_loader.batch_size, i * test_loader.batch_size + len(images))\n",
    "                ]\n",
    "                all_image_ids.extend(image_ids)\n",
    "                if not test_only:\n",
    "                    all_labels.extend(labels.numpy())\n",
    "            else:\n",
    "                # dual images case\n",
    "                for k in range(2):\n",
    "                    all_preds.extend(preds.cpu().numpy())\n",
    "                    image_ids = [\n",
    "                        os.path.basename(test_loader.dataset.data[idx][f'img_path{k + 1}']) for idx in\n",
    "                        range(i * test_loader.batch_size, i * test_loader.batch_size + len(images[k]))\n",
    "                    ]\n",
    "                    all_image_ids.extend(image_ids)\n",
    "                    if not test_only:\n",
    "                        all_labels.extend(labels.numpy())\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "    # Save predictions to csv file for Kaggle online evaluation\n",
    "    if test_only:\n",
    "        df = pd.DataFrame({\n",
    "            'ID': all_image_ids,\n",
    "            'TARGET': all_preds\n",
    "        })\n",
    "        df.to_csv(prediction_path, index=False)\n",
    "        print(f'[Test] Save predictions to {os.path.abspath(prediction_path)}')\n",
    "    else:\n",
    "        metrics = compute_metrics(all_preds, all_labels)\n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "pxhsGDIyzNxo",
   "metadata": {
    "id": "pxhsGDIyzNxo"
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, device, criterion, optimizer, lr_scheduler, num_epochs=25,\n",
    "                checkpoint_path='model.pth'):\n",
    "    best_model = model.state_dict()\n",
    "    best_epoch = None\n",
    "    best_val_kappa = -1.0  # Initialize the best kappa score\n",
    "    kappas = np.zeros(num_epochs)\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        print(f'\\nEpoch {epoch}/{num_epochs}')\n",
    "        running_loss = []\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        with tqdm(total=len(train_loader), desc=f'Training', unit=' batch', file=sys.stdout) as pbar:\n",
    "            for images, labels in train_loader:\n",
    "                if not isinstance(images, list):\n",
    "                    images = images.to(device)  # single image case\n",
    "                else:\n",
    "                    images = [x.to(device) for x in images]  # dual images case\n",
    "\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels.long())\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                preds = torch.argmax(outputs, 1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "                running_loss.append(loss.item())\n",
    "\n",
    "                pbar.set_postfix({'lr': f'{optimizer.param_groups[0][\"lr\"]:.1e}', 'Loss': f'{loss.item():.4f}'})\n",
    "                pbar.update(1)\n",
    "\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        epoch_loss = sum(running_loss) / len(running_loss)\n",
    "\n",
    "        train_metrics = compute_metrics(all_preds, all_labels, per_class=True)\n",
    "        kappa, accuracy, precision, recall = train_metrics[:4]\n",
    "\n",
    "        print(f'[Train] Kappa: {kappa:.4f} Accuracy: {accuracy:.4f} '\n",
    "              f'Precision: {precision:.4f} Recall: {recall:.4f} Loss: {epoch_loss:.4f}')\n",
    "\n",
    "        if len(train_metrics) > 4:\n",
    "            precision_per_class, recall_per_class = train_metrics[4:]\n",
    "            for i, (precision, recall) in enumerate(zip(precision_per_class, recall_per_class)):\n",
    "                print(f'[Train] Class {i}: Precision: {precision:.4f}, Recall: {recall:.4f}')\n",
    "\n",
    "        # Evaluation on the validation set at the end of each epoch\n",
    "        val_metrics = evaluate_model(model, val_loader, device)\n",
    "        val_kappa, val_accuracy, val_precision, val_recall = val_metrics[:4]\n",
    "        print(f'[Val] Kappa: {val_kappa:.4f} Accuracy: {val_accuracy:.4f} '\n",
    "              f'Precision: {val_precision:.4f} Recall: {val_recall:.4f}')\n",
    "        kappas[epoch - 1] = val_kappa\n",
    "\n",
    "        if val_kappa > best_val_kappa:\n",
    "            best_val_kappa = val_kappa\n",
    "            best_epoch = epoch\n",
    "            best_model = model.state_dict()\n",
    "            torch.save(best_model, checkpoint_path)\n",
    "\n",
    "    print(f'[Val] Best kappa: {best_val_kappa:.4f}, Epoch {best_epoch}')\n",
    "\n",
    "    return model, kappas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a9a28f5-e25c-42de-ae84-6377212e1e4f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3a9a28f5-e25c-42de-ae84-6377212e1e4f",
    "outputId": "da19c03d-73ad-4c17-c5ef-fcb2f832717b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100%|██████████| 44.7M/44.7M [00:00<00:00, 123MB/s]\n",
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
      "100%|██████████| 528M/528M [00:02<00:00, 202MB/s]\n",
      "Downloading: \"https://download.pytorch.org/models/densenet161-8d451a50.pth\" to /root/.cache/torch/hub/checkpoints/densenet161-8d451a50.pth\n",
      "100%|██████████| 110M/110M [00:00<00:00, 199MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/.cache/kagglehub/datasets/mariaherrerot/aptos2019/versions/3\n",
      "Device: cuda\n",
      "\n",
      "Epoch 1/10\n",
      "Training: 100%|██████████| 123/123 [06:00<00:00,  2.93s/ batch, lr=1.0e-04, Loss=0.1152]\n",
      "[Train] Kappa: 0.0186 Accuracy: 0.7345 Precision: 0.7534 Recall: 0.7345 Loss: 1.2679\n",
      "[Train] Class 0: Precision: 0.9358, Recall: 0.9358\n",
      "[Train] Class 1: Precision: 0.5536, Recall: 0.4300\n",
      "[Train] Class 2: Precision: 0.6435, Recall: 0.7215\n",
      "[Train] Class 3: Precision: 0.4932, Recall: 0.2338\n",
      "[Train] Class 4: Precision: 0.4429, Recall: 0.2650\n",
      "[Train] Class 5: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 6: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 7: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 8: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 9: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 10: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 11: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 12: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 13: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 14: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 15: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 16: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 17: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 18: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 19: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 20: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 21: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 22: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 23: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 24: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 25: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 26: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 27: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 28: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 29: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 30: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 31: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 32: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 33: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 34: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 35: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 36: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 37: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 38: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 39: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 40: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 41: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 42: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 43: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 44: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 45: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 46: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 47: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 48: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 49: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 50: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 51: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 52: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 53: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 54: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 55: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 56: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 57: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 58: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 59: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 60: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 61: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 62: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 63: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 64: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 65: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 66: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 67: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 68: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 69: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 70: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 71: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 72: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 73: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 74: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 75: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 76: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 77: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 78: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 79: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 80: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 81: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 82: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 83: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 84: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 85: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 86: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 87: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 88: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 89: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 90: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 91: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 92: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 93: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 94: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 95: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 96: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 97: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 98: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 99: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 100: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 101: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 102: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 103: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 104: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 105: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 106: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 107: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 108: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 109: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 110: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 111: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 112: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 113: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 114: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 115: Precision: 0.0000, Recall: 0.0000\n",
      "Evaluating: 100%|██████████| 16/16 [00:48<00:00,  3.02s/ batch]\n",
      "[Val] Kappa: 0.8493 Accuracy: 0.8033 Precision: 0.7896 Recall: 0.8033\n",
      "\n",
      "Epoch 2/10\n",
      "Training: 100%|██████████| 123/123 [06:10<00:00,  3.02s/ batch, lr=1.0e-04, Loss=1.4597]\n",
      "[Train] Kappa: 0.8920 Accuracy: 0.8509 Precision: 0.8454 Recall: 0.8509 Loss: 0.4288\n",
      "[Train] Class 0: Precision: 0.9662, Recall: 0.9756\n",
      "[Train] Class 1: Precision: 0.7113, Recall: 0.6900\n",
      "[Train] Class 2: Precision: 0.7703, Recall: 0.8676\n",
      "[Train] Class 3: Precision: 0.6289, Recall: 0.3961\n",
      "[Train] Class 4: Precision: 0.6793, Recall: 0.5342\n",
      "Evaluating: 100%|██████████| 16/16 [00:48<00:00,  3.03s/ batch]\n",
      "[Val] Kappa: 0.8569 Accuracy: 0.7814 Precision: 0.7990 Recall: 0.7814\n",
      "\n",
      "Epoch 3/10\n",
      "Training: 100%|██████████| 123/123 [06:10<00:00,  3.01s/ batch, lr=1.0e-04, Loss=6.3026]\n",
      "[Train] Kappa: 0.9292 Accuracy: 0.9078 Precision: 0.9062 Recall: 0.9078 Loss: 0.3156\n",
      "[Train] Class 0: Precision: 0.9807, Recall: 0.9902\n",
      "[Train] Class 1: Precision: 0.8299, Recall: 0.8133\n",
      "[Train] Class 2: Precision: 0.8540, Recall: 0.9047\n",
      "[Train] Class 3: Precision: 0.8140, Recall: 0.6818\n",
      "[Train] Class 4: Precision: 0.7882, Recall: 0.6838\n",
      "Evaluating: 100%|██████████| 16/16 [00:48<00:00,  3.05s/ batch]\n",
      "[Val] Kappa: 0.8638 Accuracy: 0.8005 Precision: 0.8124 Recall: 0.8005\n",
      "\n",
      "Epoch 4/10\n",
      "Training: 100%|██████████| 123/123 [06:09<00:00,  3.01s/ batch, lr=1.0e-04, Loss=7.0141]\n",
      "[Train] Kappa: 0.9397 Accuracy: 0.9212 Precision: 0.9201 Recall: 0.9212 Loss: 0.2839\n",
      "[Train] Class 0: Precision: 0.9731, Recall: 0.9840\n",
      "[Train] Class 1: Precision: 0.8516, Recall: 0.8033\n",
      "[Train] Class 2: Precision: 0.8859, Recall: 0.9220\n",
      "[Train] Class 3: Precision: 0.8345, Recall: 0.7857\n",
      "[Train] Class 4: Precision: 0.8578, Recall: 0.7735\n",
      "Evaluating: 100%|██████████| 16/16 [00:48<00:00,  3.04s/ batch]\n",
      "[Val] Kappa: 0.8544 Accuracy: 0.7951 Precision: 0.7942 Recall: 0.7951\n",
      "\n",
      "Epoch 5/10\n",
      "Training: 100%|██████████| 123/123 [06:10<00:00,  3.01s/ batch, lr=1.0e-04, Loss=0.0202]\n",
      "[Train] Kappa: 0.9625 Accuracy: 0.9444 Precision: 0.9439 Recall: 0.9444 Loss: 0.1752\n",
      "[Train] Class 0: Precision: 0.9896, Recall: 0.9909\n",
      "[Train] Class 1: Precision: 0.8808, Recall: 0.8867\n",
      "[Train] Class 2: Precision: 0.9238, Recall: 0.9455\n",
      "[Train] Class 3: Precision: 0.8333, Recall: 0.7792\n",
      "[Train] Class 4: Precision: 0.8869, Recall: 0.8376\n",
      "Evaluating: 100%|██████████| 16/16 [00:48<00:00,  3.04s/ batch]\n",
      "[Val] Kappa: 0.8881 Accuracy: 0.8361 Precision: 0.8417 Recall: 0.8361\n",
      "\n",
      "Epoch 6/10\n",
      "Training: 100%|██████████| 123/123 [06:10<00:00,  3.01s/ batch, lr=1.0e-04, Loss=1.8559]\n",
      "[Train] Kappa: 0.9791 Accuracy: 0.9696 Precision: 0.9695 Recall: 0.9696 Loss: 0.1186\n",
      "[Train] Class 0: Precision: 0.9944, Recall: 0.9958\n",
      "[Train] Class 1: Precision: 0.9465, Recall: 0.9433\n",
      "[Train] Class 2: Precision: 0.9595, Recall: 0.9678\n",
      "[Train] Class 3: Precision: 0.9007, Recall: 0.8831\n",
      "[Train] Class 4: Precision: 0.9258, Recall: 0.9060\n",
      "Evaluating: 100%|██████████| 16/16 [00:48<00:00,  3.04s/ batch]\n",
      "[Val] Kappa: 0.8821 Accuracy: 0.8087 Precision: 0.8264 Recall: 0.8087\n",
      "\n",
      "Epoch 7/10\n",
      "Training: 100%|██████████| 123/123 [06:11<00:00,  3.02s/ batch, lr=1.0e-04, Loss=3.1083]\n",
      "[Train] Kappa: 0.9742 Accuracy: 0.9652 Precision: 0.9652 Recall: 0.9652 Loss: 0.1307\n",
      "[Train] Class 0: Precision: 0.9951, Recall: 0.9972\n",
      "[Train] Class 1: Precision: 0.9637, Recall: 0.9733\n",
      "[Train] Class 2: Precision: 0.9525, Recall: 0.9431\n",
      "[Train] Class 3: Precision: 0.8608, Recall: 0.8831\n",
      "[Train] Class 4: Precision: 0.8966, Recall: 0.8889\n",
      "Evaluating: 100%|██████████| 16/16 [00:48<00:00,  3.05s/ batch]\n",
      "[Val] Kappa: 0.8827 Accuracy: 0.8279 Precision: 0.8216 Recall: 0.8279\n",
      "\n",
      "Epoch 8/10\n",
      "Training: 100%|██████████| 123/123 [06:10<00:00,  3.01s/ batch, lr=1.0e-04, Loss=2.0722]\n",
      "[Train] Kappa: 0.9850 Accuracy: 0.9754 Precision: 0.9754 Recall: 0.9754 Loss: 0.1090\n",
      "[Train] Class 0: Precision: 0.9923, Recall: 0.9923\n",
      "[Train] Class 1: Precision: 0.9525, Recall: 0.9367\n",
      "[Train] Class 2: Precision: 0.9717, Recall: 0.9790\n",
      "[Train] Class 3: Precision: 0.9338, Recall: 0.9156\n",
      "[Train] Class 4: Precision: 0.9407, Recall: 0.9487\n",
      "Evaluating: 100%|██████████| 16/16 [00:48<00:00,  3.03s/ batch]\n",
      "[Val] Kappa: 0.8816 Accuracy: 0.8333 Precision: 0.8277 Recall: 0.8333\n",
      "\n",
      "Epoch 9/10\n",
      "Training: 100%|██████████| 123/123 [06:10<00:00,  3.01s/ batch, lr=1.0e-04, Loss=0.0039]\n",
      "[Train] Kappa: 0.9841 Accuracy: 0.9724 Precision: 0.9723 Recall: 0.9724 Loss: 0.0910\n",
      "[Train] Class 0: Precision: 0.9916, Recall: 0.9937\n",
      "[Train] Class 1: Precision: 0.9461, Recall: 0.9367\n",
      "[Train] Class 2: Precision: 0.9597, Recall: 0.9728\n",
      "[Train] Class 3: Precision: 0.9392, Recall: 0.9026\n",
      "[Train] Class 4: Precision: 0.9520, Recall: 0.9316\n",
      "Evaluating: 100%|██████████| 16/16 [00:48<00:00,  3.04s/ batch]\n",
      "[Val] Kappa: 0.8615 Accuracy: 0.8115 Precision: 0.8091 Recall: 0.8115\n",
      "\n",
      "Epoch 10/10\n",
      "Training: 100%|██████████| 123/123 [06:10<00:00,  3.01s/ batch, lr=1.0e-04, Loss=2.1592]\n",
      "[Train] Kappa: 0.9861 Accuracy: 0.9792 Precision: 0.9792 Recall: 0.9792 Loss: 0.0872\n",
      "[Train] Class 0: Precision: 0.9979, Recall: 0.9965\n",
      "[Train] Class 1: Precision: 0.9570, Recall: 0.9633\n",
      "[Train] Class 2: Precision: 0.9693, Recall: 0.9765\n",
      "[Train] Class 3: Precision: 0.9351, Recall: 0.9351\n",
      "[Train] Class 4: Precision: 0.9561, Recall: 0.9316\n",
      "Evaluating: 100%|██████████| 16/16 [00:48<00:00,  3.03s/ batch]\n",
      "[Val] Kappa: 0.8872 Accuracy: 0.8115 Precision: 0.8204 Recall: 0.8115\n",
      "[Val] Best kappa: 0.8881, Epoch 5\n"
     ]
    }
   ],
   "source": [
    "# Create datasets\n",
    "resnet18 = (\"ResNET\", models.resnet18(weights=models.ResNet18_Weights.DEFAULT))\n",
    "vgg16 = (\"VGG\", models.vgg16(weights=models.VGG16_Weights.DEFAULT))\n",
    "densenet161 = (\"DenseNET\", models.densenet161(weights=models.DenseNet161_Weights.DEFAULT))\n",
    "name, model = resnet18\n",
    "name = \"APTOS-\" + name\n",
    "print(path)\n",
    "train_dataset = APTOSDataset(path + '/train_1.csv', path + '/train_images/train_images/', preprocess)\n",
    "val_dataset = APTOSDataset(path + '/valid.csv', path + '/val_images/val_images/', preprocess)\n",
    "test_dataset = APTOSDataset(path + '/test.csv', path + '/test_images/test_images/', preprocess, test=True)\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Define the weighted CrossEntropyLoss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Use GPU device is possible\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device:', device)\n",
    "\n",
    "# Move class weights to the device\n",
    "model = model.to(device)\n",
    "\n",
    "# Optimizer and Learning rate scheduler\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "# Train and evaluate the model with the training and validation set\n",
    "model, kappas = train_model(\n",
    "    model, train_loader, val_loader, device, criterion, optimizer,\n",
    "    lr_scheduler=lr_scheduler, num_epochs=num_epochs,\n",
    "    checkpoint_path='./model_aptos-2019-pretrained.pth'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "P57RGt7bF2_1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P57RGt7bF2_1",
    "outputId": "81268c58-55eb-48fc-8f32-9c9943263598"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-308010b2a7c2>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load('./model_aptos-2019-pretrained.pth', map_location='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 16/16 [00:42<00:00,  2.69s/ batch]\n",
      "[Test] Save predictions to /content/test_predictions_ResNET.csv\n"
     ]
    }
   ],
   "source": [
    "state_dict = torch.load('./model_aptos-2019-pretrained.pth', map_location='cpu')\n",
    "model.load_state_dict(state_dict, strict=True)\n",
    "evaluate_model(model, test_loader, device, test_only=True, prediction_path=\"./test_predictions_{}.csv\".format(name))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
