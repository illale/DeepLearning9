{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10328241,"sourceType":"datasetVersion","datasetId":6395053},{"sourceId":10334821,"sourceType":"datasetVersion","datasetId":6399293},{"sourceId":215012279,"sourceType":"kernelVersion"}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"18b67724-a3fe-44b0-bcf8-f1883d984cab","cell_type":"code","source":"import copy\nimport os\nimport random\nimport sys\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nfrom PIL import Image\nfrom sklearn.metrics import cohen_kappa_score, precision_score, recall_score, accuracy_score\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import models, transforms\nfrom torchvision.transforms.functional import to_pil_image\nfrom tqdm import tqdm\nimport torch.nn.functional as F\n# from library import *","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T09:23:41.207713Z","iopub.execute_input":"2024-12-31T09:23:41.208064Z","iopub.status.idle":"2024-12-31T09:23:41.212940Z","shell.execute_reply.started":"2024-12-31T09:23:41.208034Z","shell.execute_reply":"2024-12-31T09:23:41.212079Z"}},"outputs":[],"execution_count":7},{"id":"b8e3a56a-4af4-463d-8bac-24610e74c646","cell_type":"code","source":"import copy\nimport os\nimport random\nimport sys\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nfrom PIL import Image\nfrom sklearn.metrics import cohen_kappa_score, precision_score, recall_score, accuracy_score\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import models, transforms\nfrom torchvision.transforms.functional import to_pil_image\nfrom tqdm import tqdm\n\nclass RetinopathyDataset(Dataset):\n    def __init__(self, ann_file, image_dir, transform=None, mode='single', test=False):\n        self.ann_file = ann_file\n        self.image_dir = image_dir\n        self.transform = transform\n\n        self.test = test\n        self.mode = mode\n        self.default_transform = transforms.Compose([\n                        transforms.Resize((224, 224)),\n                        transforms.ToTensor(),\n                        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n            ])\n\n        if self.mode == 'single':\n            self.data = self.load_data()\n            self.sp = len(self.data)\n            self.data.extend(self.data)\n            \n        else:\n            self.data = self.load_data_dual()\n            self.sp = len(self.data)\n            self.data.extend(self.data)\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, index):\n        if self.mode == 'single':\n            return self.get_item(index)\n        else:\n            return self.get_item_dual(index)\n\n    # 1. single image\n    def load_data(self):\n        df = pd.read_csv(self.ann_file)\n\n        data = []\n        for _, row in df.iterrows():\n            file_info = dict()\n            file_info['img_path'] = os.path.join(self.image_dir, row['img_path'])\n            if not self.test:\n                file_info['dr_level'] = int(row['patient_DR_Level'])\n            data.append(file_info)\n        return data\n\n    def get_item(self, index):\n        data = self.data[index]\n        img = Image.open(data['img_path']).convert('RGB')\n        r = random.random()\n        if self.transform and index >= self.sp:\n            img = self.transform(img)\n        else: \n            img = self.default_transform(img)\n            \n\n        if not self.test:\n            label = torch.tensor(data['dr_level'], dtype=torch.int64)\n            return img, label\n        else:\n            return img\n\n    # 2. dual image\n    def load_data_dual(self):\n        df = pd.read_csv(self.ann_file)\n\n        df['prefix'] = df['image_id'].str.split('_').str[0]  # The patient id of each image\n        df['suffix'] = df['image_id'].str.split('_').str[1].str[0]  # The left or right eye\n        grouped = df.groupby(['prefix', 'suffix'])\n\n        data = []\n        for (prefix, suffix), group in grouped:\n            file_info = dict()\n            file_info['img_path1'] = os.path.join(self.image_dir, group.iloc[0]['img_path'])\n            file_info['img_path2'] = os.path.join(self.image_dir, group.iloc[1]['img_path'])\n            if not self.test:\n                file_info['dr_level'] = int(group.iloc[0]['patient_DR_Level'])\n            data.append(file_info)\n        return data\n\n    def get_item_dual(self, index):\n        data = self.data[index]\n        img1 = Image.open(data['img_path1']).convert('RGB')\n        img2 = Image.open(data['img_path2']).convert('RGB')\n\n        if self.transform and index >= self.sp:\n            img1 = self.transform(img1)\n            img2 = self.transform(img2)\n        else: \n            img1 = self.default_transform(img1)\n            img2 = self.default_transform(img2)\n\n        if not self.test:\n            label = torch.tensor(data['dr_level'], dtype=torch.int64)\n            return [img1, img2], label\n        else:\n            return [img1, img2]\n\nclass SLORandomPad:\n    def __init__(self, size):\n        self.size = size\n\n    def __call__(self, img):\n        pad_width = max(0, self.size[0] - img.width)\n        pad_height = max(0, self.size[1] - img.height)\n        pad_left = random.randint(0, pad_width)\n        pad_top = random.randint(0, pad_height)\n        pad_right = pad_width - pad_left\n        pad_bottom = pad_height - pad_top\n        return transforms.functional.pad(img, (pad_left, pad_top, pad_right, pad_bottom))\n\nclass FundRandomRotate:\n    def __init__(self, prob, degree):\n        self.prob = prob\n        self.degree = degree\n\n    def __call__(self, img):\n        if random.random() < self.prob:\n            angle = random.uniform(-self.degree, self.degree)\n            return transforms.functional.rotate(img, angle)\n        return img\n\ndef train_model(model, train_loader, val_loader, device, criterion, optimizer, lr_scheduler, num_epochs=25,\n                checkpoint_path='model.pth'):\n    best_model = model.state_dict()\n    best_epoch = None\n    best_val_kappa = -1.0  # Initialize the best kappa score\n    kappas = np.zeros(num_epochs)\n\n    for epoch in range(1, num_epochs + 1):\n        print(f'\\nEpoch {epoch}/{num_epochs}')\n        running_loss = []\n        all_preds = []\n        all_labels = []\n\n        model.train()\n\n        with tqdm(total=len(train_loader), desc=f'Training', unit=' batch', file=sys.stdout) as pbar:\n            for images, labels in train_loader:\n                if not isinstance(images, list):\n                    images = images.to(device)  # single image case\n                else:\n                    images = [x.to(device) for x in images]  # dual images case\n\n                labels = labels.to(device)\n\n                optimizer.zero_grad()\n\n                outputs = model(images)\n                loss = criterion(outputs, labels.long())\n\n                loss.backward()\n                optimizer.step()\n\n                preds = torch.argmax(outputs, 1)\n                all_preds.extend(preds.cpu().numpy())\n                all_labels.extend(labels.cpu().numpy())\n\n                running_loss.append(loss.item())\n\n                pbar.set_postfix({'lr': f'{optimizer.param_groups[0][\"lr\"]:.1e}', 'Loss': f'{loss.item():.4f}'})\n                pbar.update(1)\n\n        lr_scheduler.step()\n\n        epoch_loss = sum(running_loss) / len(running_loss)\n\n        train_metrics = compute_metrics(all_preds, all_labels, per_class=True)\n        kappa, accuracy, precision, recall = train_metrics[:4]\n\n        print(f'[Train] Kappa: {kappa:.4f} Accuracy: {accuracy:.4f} '\n              f'Precision: {precision:.4f} Recall: {recall:.4f} Loss: {epoch_loss:.4f}')\n\n        if len(train_metrics) > 4:\n            precision_per_class, recall_per_class = train_metrics[4:]\n            for i, (precision, recall) in enumerate(zip(precision_per_class, recall_per_class)):\n                print(f'[Train] Class {i}: Precision: {precision:.4f}, Recall: {recall:.4f}')\n\n        # Evaluation on the validation set at the end of each epoch\n        val_metrics = evaluate_model(model, val_loader, device)\n        val_kappa, val_accuracy, val_precision, val_recall = val_metrics[:4]\n        print(f'[Val] Kappa: {val_kappa:.4f} Accuracy: {val_accuracy:.4f} '\n              f'Precision: {val_precision:.4f} Recall: {val_recall:.4f}')\n        kappas[epoch - 1] = val_kappa\n\n        if val_kappa > best_val_kappa:\n            best_val_kappa = val_kappa\n            best_epoch = epoch\n            best_model = model.state_dict()\n            torch.save(best_model, checkpoint_path)\n\n    print(f'[Val] Best kappa: {best_val_kappa:.4f}, Epoch {best_epoch}')\n\n    return model, kappas\n\ndef evaluate_model(model, test_loader, device, test_only=False, prediction_path='./test_predictions.csv'):\n    model.eval()\n\n    all_preds = []\n    all_labels = []\n    all_image_ids = []\n\n    with tqdm(total=len(test_loader), desc=f'Evaluating', unit=' batch', file=sys.stdout) as pbar:\n        for i, data in enumerate(test_loader):\n\n            if test_only:\n                images = data\n            else:\n                images, labels = data\n\n            if not isinstance(images, list):\n                images = images.to(device)  # single image case\n            else:\n                images = [x.to(device) for x in images]  # dual images case\n\n            with torch.no_grad():\n                outputs = model(images)\n                preds = torch.argmax(outputs, 1)\n\n            if not isinstance(images, list):\n                # single image case\n                all_preds.extend(preds.cpu().numpy())\n                image_ids = [\n                    os.path.basename(test_loader.dataset.data[idx]['img_path']) for idx in\n                    range(i * test_loader.batch_size, i * test_loader.batch_size + len(images))\n                ]\n                all_image_ids.extend(image_ids)\n                if not test_only:\n                    all_labels.extend(labels.numpy())\n            else:\n                # dual images case\n                for k in range(2):\n                    all_preds.extend(preds.cpu().numpy())\n                    image_ids = [\n                        os.path.basename(test_loader.dataset.data[idx][f'img_path{k + 1}']) for idx in\n                        range(i * test_loader.batch_size, i * test_loader.batch_size + len(images[k]))\n                    ]\n                    all_image_ids.extend(image_ids)\n                    if not test_only:\n                        all_labels.extend(labels.numpy())\n\n            pbar.update(1)\n\n    # Save predictions to csv file for Kaggle online evaluation\n    if test_only:\n        df = pd.DataFrame({\n            'ID': all_image_ids,\n            'TARGET': all_preds\n        })\n        df.to_csv(prediction_path, index=False)\n        print(f'[Test] Save predictions to {os.path.abspath(prediction_path)}')\n    else:\n        metrics = compute_metrics(all_preds, all_labels)\n        return metrics\n\ndef compute_metrics(preds, labels, per_class=False):\n    kappa = cohen_kappa_score(labels, preds, weights='quadratic')\n    accuracy = accuracy_score(labels, preds)\n    precision = precision_score(labels, preds, average='weighted', zero_division=0)\n    recall = recall_score(labels, preds, average='weighted', zero_division=0)\n\n    # Calculate and print precision and recall for each class\n    if per_class:\n        precision_per_class = precision_score(labels, preds, average=None, zero_division=0)\n        recall_per_class = recall_score(labels, preds, average=None, zero_division=0)\n        return kappa, accuracy, precision, recall, precision_per_class, recall_per_class\n\n    return kappa, accuracy, precision, recall","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T09:23:41.213934Z","iopub.execute_input":"2024-12-31T09:23:41.214186Z","iopub.status.idle":"2024-12-31T09:23:41.243526Z","shell.execute_reply.started":"2024-12-31T09:23:41.214166Z","shell.execute_reply":"2024-12-31T09:23:41.242595Z"}},"outputs":[],"execution_count":8},{"id":"6a408247-f7c1-464c-a882-c909ceda7c9d","cell_type":"code","source":"torch.manual_seed(0)\nbatch_size = 24\nnum_classes = 5  # 5 DR levels\nlearning_rate = 0.0001\nnum_epochs = 20\ndataset_folder = \"/kaggle/input/finaldeeplearning/521153S-3005-final-project\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T09:23:41.311375Z","iopub.execute_input":"2024-12-31T09:23:41.311693Z","iopub.status.idle":"2024-12-31T09:23:41.316553Z","shell.execute_reply.started":"2024-12-31T09:23:41.311660Z","shell.execute_reply":"2024-12-31T09:23:41.315741Z"}},"outputs":[],"execution_count":9},{"id":"8b455dc0-283a-433a-b47b-c75ab0af3860","cell_type":"code","source":"transform_train = transforms.Compose([\n    transforms.Resize((256, 256)),\n    transforms.RandomCrop((210, 210)),\n    SLORandomPad((224, 224)),\n    FundRandomRotate(prob=0.5, degree=30),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomVerticalFlip(p=0.5),\n    transforms.RandomRotation(90),\n    transforms.ColorJitter(brightness=(0.1, 0.9)),\n    transforms.RandomInvert(p=0.7), # 0.7\n    transforms.RandomGrayscale(p=0.5), # 0.5\n    transforms.RandomPerspective(p=0.3), # 0.3    \n    transforms.GaussianBlur(kernel_size=5), # 5\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\ntransform_test = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T09:23:41.317701Z","iopub.execute_input":"2024-12-31T09:23:41.317918Z","iopub.status.idle":"2024-12-31T09:23:41.332752Z","shell.execute_reply.started":"2024-12-31T09:23:41.317900Z","shell.execute_reply":"2024-12-31T09:23:41.331941Z"}},"outputs":[],"execution_count":10},{"id":"7f739bc7-e582-4d42-8656-212fde057008","cell_type":"code","source":"def train_and_save(model, name, num_epochs=10): \n    train_dataset = RetinopathyDataset(data_path+'/DeepDRiD/train.csv', data_path+'/DeepDRiD/train/', transform_train, mode)\n    val_dataset = RetinopathyDataset(data_path+'./DeepDRiD/val.csv', data_path+'/DeepDRiD/val/', transform_test, mode)\n    test_dataset = RetinopathyDataset(data_path+'./DeepDRiD/test.csv', data_path+'/DeepDRiD/test/', transform_test, mode, test=True)\n    \n    # Create dataloaders\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n    \n    # Define the weighted CrossEntropyLoss\n    criterion = nn.CrossEntropyLoss()\n    \n    # Use GPU device is possible\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    print('Device:', device)\n    \n    # Move class weights to the device\n    model = model.to(device)\n    \n    # Optimizer and Learning rate scheduler\n    optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate)\n    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n    \n    # Train and evaluate the model with the training and validation set\n    model, kappas = train_model(\n        model, train_loader, val_loader, device, criterion, optimizer,\n        lr_scheduler=lr_scheduler, num_epochs=num_epochs,\n        checkpoint_path='./aptos-resnet-deepdrip_{}.pth'.format(name)\n    )\n\n    # Load the pretrained checkpoint\n    state_dict = torch.load('./aptos-resnet-deepdrip_{}.pth'.format(name), map_location='cpu')\n    model.load_state_dict(state_dict, strict=True)\n    \n    # Make predictions on testing set and save the prediction results\n    evaluate_model(model, test_loader, device, test_only=True, prediction_path=\"./test_predictions_aptos-{}-deepdrip.csv\".format(name))\n    return model, kappas","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T09:23:41.334195Z","iopub.execute_input":"2024-12-31T09:23:41.334490Z","iopub.status.idle":"2024-12-31T09:23:41.353467Z","shell.execute_reply.started":"2024-12-31T09:23:41.334463Z","shell.execute_reply":"2024-12-31T09:23:41.352699Z"}},"outputs":[],"execution_count":11},{"id":"c2b60663-18e2-41e0-9970-3d539d054344","cell_type":"code","source":"densenet_model_path = \"/kaggle/input/models/models/aptos-resnet-deepdrip_densenet.pth\"\nresnet_model_path = \"/kaggle/input/models/models/aptos-resnet-deepdrip_resnet.pth\"\nvgg_model_path = \"/kaggle/input/models/models/aptos-resnet-deepdrip_vgg.pth\"\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nresnet_model = models.resnet18()\nname = \"resnet\"\nstate_dict = torch.load(resnet_model_path, map_location=device,weights_only=\"True\")\nresnet_model.load_state_dict(state_dict, strict=True)\n\nvgg_model = models.vgg16()\nname = \"vgg\"\nstate_dict = torch.load(vgg_model_path, map_location=device,weights_only=\"True\")\nvgg_model.load_state_dict(state_dict, strict=True)\n\ndensenet_model = models.densenet161()\nname = \"densenet\"\nstate_dict = torch.load(densenet_model_path, map_location=device,weights_only=\"True\")\ndensenet_model.load_state_dict(state_dict, strict=True)\n\n\n# Define dataset and loaders\nmode = 'single'\ndata_path = \"/kaggle/input/finaldeeplearning/521153S-3005-final-project/\"\ntrain_dataset = RetinopathyDataset(data_path+'DeepDRiD/train.csv', data_path+'DeepDRiD/train/', transform_train, mode)\nval_dataset = RetinopathyDataset(data_path+'DeepDRiD/val.csv', data_path+'DeepDRiD/val/', transform_test, mode)\ntest_dataset = RetinopathyDataset(data_path+'DeepDRiD/test.csv', data_path+'DeepDRiD/test/', transform_test, mode, test=True)\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\n\ncandidate_models = [resnet_model,vgg_model,densenet_model]\ncandidate_models = [model.to(device) for model in candidate_models]\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T10:30:54.618384Z","iopub.execute_input":"2024-12-31T10:30:54.618723Z","iopub.status.idle":"2024-12-31T10:30:58.576516Z","shell.execute_reply.started":"2024-12-31T10:30:54.618696Z","shell.execute_reply":"2024-12-31T10:30:58.575592Z"}},"outputs":[],"execution_count":35},{"id":"cfbf4817-95ba-45d9-b709-d397a7e47a89","cell_type":"code","source":"def generate_predictions(models, data_loader, device):\n    \"\"\"\n    Generate predictions for a list of models and collect ground truths from the data loader.\n\n    Args:\n        models (list): List of models to generate predictions from.\n        data_loader (DataLoader): DataLoader object for input data.\n        device (torch.device): Device to run the models on.\n\n    Returns:\n        model_predictions (list): List of numpy arrays, one for each model's predictions.\n        ground_truths (np.array): Ground truth labels for the data loader.\n    \"\"\"\n    # Step 1: Collect ground truths\n    ground_truths = []\n    for _, labels in data_loader:\n        if isinstance(labels, torch.Tensor):\n            labels = labels.numpy()\n        ground_truths.extend(labels)\n    ground_truths = np.array(ground_truths)\n\n    # Step 2: Generate predictions for each model\n    model_predictions = []  # To store predictions from each model\n\n    for model in models:\n        model.eval()  # Set model to evaluation mode\n        all_preds = []  # Collect predictions for this model\n\n        with torch.no_grad():\n            for images, _ in data_loader:  # Only need images during prediction\n                images = images.to(device)\n\n                # Forward pass through the model\n                outputs = model(images)\n                # outputs = outputs[:,:5]\n                probabilities = F.softmax(outputs, dim=1).cpu().numpy()  # Convert logits to probabilities\n                all_preds.append(probabilities)  # Store predictions\n\n        # Combine all batch predictions for the current model\n        model_predictions.append(np.vstack(all_preds))  # Stack all predictions\n    # model_predictions = model_predictions[,:5]\n    return model_predictions, ground_truths\na,b = generate_predictions(candidate_models, val_loader, device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T10:30:59.072891Z","iopub.execute_input":"2024-12-31T10:30:59.073245Z","iopub.status.idle":"2024-12-31T10:31:24.720371Z","shell.execute_reply.started":"2024-12-31T10:30:59.073206Z","shell.execute_reply":"2024-12-31T10:31:24.719667Z"}},"outputs":[],"execution_count":36},{"id":"a005d61f-73f5-4cea-8905-9094f0e41d3c","cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nfrom scipy.stats import mode\nimport numpy as np\nimport torch\n\ndef stacking(candidate_models, train_loader, val_loader, device):\n    # Step 1: Generate predictions on training data for the meta-model\n    train_predictions, train_labels = generate_predictions(candidate_models, train_loader, device)\n    X_train = np.hstack(train_predictions)  # Training features for meta-model\n    y_train = train_labels  # Ground truth labels for training\n\n    # Step 2: Generate predictions on validation data for evaluation\n    val_predictions, val_labels = generate_predictions(candidate_models, val_loader, device)\n    X_val = np.hstack(val_predictions)  # Validation features for meta-model\n\n    # Step 3: Train the meta-model\n    meta_model = LogisticRegression(max_iter=1000)\n    meta_model.fit(X_train, y_train)\n\n    # Step 4: Predict on training and validation sets using the meta-model\n    y_train_pred = meta_model.predict(X_train)\n    y_val_pred = meta_model.predict(X_val)\n\n    # Calculate accuracy for the training set\n    train_accuracy = accuracy_score(y_train, y_train_pred)\n    print(f\"Meta-Model Training Accuracy: {train_accuracy:.4f}\")\n\n    return y_val_pred\n\ndef weighted_average(candidate_models, train_loader, val_loader, device):\n    train_predictions, train_labels = generate_predictions(candidate_models, train_loader, device)\n    weights = [accuracy_score(train_labels, np.argmax(preds, axis=1)) for preds in train_predictions]\n    weights = np.array(weights) / sum(weights)\n\n    val_predictions, _ = generate_predictions(candidate_models, val_loader, device)\n    weighted_val_preds = sum(w * preds for w, preds in zip(weights, val_predictions))\n    final_predictions = np.argmax(weighted_val_preds, axis=1)\n    return final_predictions\n\ndef max_voting(candidate_models, val_loader, device):\n    val_predictions, _ = generate_predictions(candidate_models, val_loader, device)\n    class_predictions = [np.argmax(preds, axis=1) for preds in val_predictions]\n    final_predictions = mode(np.column_stack(class_predictions), axis=1).mode.flatten()\n    return final_predictions\n\ndef evaluate_ensemble_methods(candidate_models, train_loader, val_loader, device):\n    \"\"\"\n    Evaluate ensemble methods using the validation set as the test set.\n    \"\"\"\n    # Extract ground truth labels for the validation dataset\n    print(\"\\nExtracting ground truth labels from the validation loader...\")\n    val_labels = []\n    for _, labels in val_loader:\n        val_labels.extend(labels.numpy())\n    val_labels = np.array(val_labels)  # Convert to numpy array\n\n    # Stacking\n    print(\"\\nEvaluating Stacking...\")\n    stacking_preds = stacking(candidate_models, train_loader, val_loader,device)\n    stacking_metrics = compute_metrics(stacking_preds, val_labels, per_class=True)\n    print_metrics(\"Stacking\", stacking_metrics)\n\n    # Weighted Average\n    print(\"\\nEvaluating Weighted Average...\")\n    weighted_preds = weighted_average(candidate_models, train_loader,val_loader, device)\n    weighted_metrics = compute_metrics(weighted_preds, val_labels, per_class=True)\n    print_metrics(\"Weighted Average\", weighted_metrics)\n\n    # Max Voting\n    print(\"\\nEvaluating Max Voting...\")\n    voting_preds = max_voting(candidate_models, val_loader, device)\n    voting_metrics = compute_metrics(voting_preds, val_labels, per_class=True)\n    print_metrics(\"Max Voting\", voting_metrics)\n\ndef print_metrics(method_name, metrics):\n    \"\"\"\n    Print the metrics for a specific ensemble method.\n    \"\"\"\n    kappa, accuracy, precision, recall = metrics[:4]\n    print(f\"=== {method_name} ===\")\n    print(f\"Kappa: {kappa:.4f}\")\n    print(f\"Accuracy: {accuracy:.4f}\")\n    print(f\"Precision (Weighted): {precision:.4f}\")\n    print(f\"Recall (Weighted): {recall:.4f}\")\n    \n    # Print per-class precision and recall if available\n    if len(metrics) > 4:\n        precision_per_class, recall_per_class = metrics[4:]\n        for i, (p, r) in enumerate(zip(precision_per_class, recall_per_class)):\n            print(f\"Class {i}: Precision: {p:.4f}, Recall: {r:.4f}\")\nevaluate_ensemble_methods(candidate_models, train_loader, val_loader, device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T10:31:24.721517Z","iopub.execute_input":"2024-12-31T10:31:24.721803Z","iopub.status.idle":"2024-12-31T10:36:16.398088Z","shell.execute_reply.started":"2024-12-31T10:31:24.721776Z","shell.execute_reply":"2024-12-31T10:36:16.397254Z"}},"outputs":[{"name":"stdout","text":"\nExtracting ground truth labels from the validation loader...\n\nEvaluating Stacking...\nMeta-Model Training Accuracy: 0.8662\n=== Stacking ===\nKappa: 0.8430\nAccuracy: 0.6900\nPrecision (Weighted): 0.6964\nRecall (Weighted): 0.6900\nClass 0: Precision: 0.8478, Recall: 0.9750\nClass 1: Precision: 0.7037, Recall: 0.4750\nClass 2: Precision: 0.4623, Recall: 0.6125\nClass 3: Precision: 0.7778, Recall: 0.7000\nClass 4: Precision: 0.5333, Recall: 0.4000\n\nEvaluating Weighted Average...\n=== Weighted Average ===\nKappa: 0.8590\nAccuracy: 0.7050\nPrecision (Weighted): 0.7026\nRecall (Weighted): 0.7050\nClass 0: Precision: 0.8500, Recall: 0.9917\nClass 1: Precision: 0.7321, Recall: 0.5125\nClass 2: Precision: 0.5000, Recall: 0.6000\nClass 3: Precision: 0.7143, Recall: 0.7500\nClass 4: Precision: 0.5833, Recall: 0.3500\n\nEvaluating Max Voting...\n=== Max Voting ===\nKappa: 0.8539\nAccuracy: 0.6875\nPrecision (Weighted): 0.6792\nRecall (Weighted): 0.6875\nClass 0: Precision: 0.8500, Recall: 0.9917\nClass 1: Precision: 0.6562, Recall: 0.5250\nClass 2: Precision: 0.4667, Recall: 0.5250\nClass 3: Precision: 0.7024, Recall: 0.7375\nClass 4: Precision: 0.5909, Recall: 0.3250\n","output_type":"stream"}],"execution_count":37},{"id":"73c89ce5-1566-4404-99d5-a3815c8bc59b","cell_type":"code","source":"evaluate_ensemble_methods(candidate_models,train_loader, val_loader, device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T09:23:41.577652Z","iopub.status.idle":"2024-12-31T09:23:41.577967Z","shell.execute_reply":"2024-12-31T09:23:41.577823Z"}},"outputs":[],"execution_count":null}]}